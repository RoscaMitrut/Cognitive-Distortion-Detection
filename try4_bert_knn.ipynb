{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoscaMitrut\\.conda\\envs\\tfgpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score,f1_score\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "therapis_responses = pd.read_csv(\"data/Therapist_responses.csv\",delimiter=\",\")\n",
    "annotated_data = pd.read_csv(\"data/Annotated_data.csv\",delimiter=\",\")\n",
    "annotated_data_copy = pd.merge(therapis_responses,annotated_data,on='Id_Number')\n",
    "annotated_data_copy = annotated_data_copy.drop(['Question'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distorsion_binary(row):\n",
    "    if row[\"Dominant Distortion\"] == \"No Distortion\":\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "annotated_data_copy[\"Distortion\"] = annotated_data_copy.apply(label_distorsion_binary, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thank you for writing. You did nothing wrong! You did not put this woman in prison. She did it to herself. She befriended, manipulated and abused a vulnerable 14-year-old (actually, two young teens). She is a sexual offender who was grooming you, not loving you. She belongs in jail.This was never an equal or appropriate relationship. As a teacher, she used her position of authority and the fact you were needy and looked up to her as means to draw you in. She was so good at gaslighting you that you believed and still believe that her abuse was love. She did all the classic moves of an abuser: She gained control of you by making you think you were special. She isolated you, making you more and more dependent on her. She created a relationship where you were always on eggshells, trying not to say or do anything that would cause a fight. She created fights anyway and then made you feel like you were at fault. Apologies and presents followed — which only confused you more. Any time that you questioned her or the relationship, she blamed and shamed you. While demanding total loyalty to her, she was disloyal to you.Don’t blame yourself! You are thinking and feeling and acting like many survivors of abuse. You are still confused. You are still taking blame on yourself. Your abuser may be in prison, but she is still in your head.I don’t know why you stopped seeing a psychologist. You do need help to sort this out. An experienced therapist will not judge you. Your feelings are recognizable for what they are — a reaction to prolonged abuse. Sadly, your experience is not unique or as complex as you believe it is. We therapists often, too often, see something like it.Please. Make an appointment with a licensed mental health counselor who specializes in trauma. You have recovery work to do. You deserve to free yourself of the blame and shame so that you can find real love in a real relationship.I wish you well. ',\n",
       " 0,\n",
       " 'From a teen in Australia: This story is incredibly long but I’m going to do my best to cut it down and only include the most important bits. When I was 14 and in a very low place, I met a teacher at my school. She was around 30. I didn’t think much of it at first, but eventually I kept talking to her more and more and seeing her around. We grew close quickly and for some reason I just felt connected to her. One day I received a text message from her as she had gotten my number off another student.',\n",
       " 'We grew close quickly and for some reason I just felt connected to her.',\n",
       " 'Emotional Reasoning',\n",
       " nan,\n",
       " 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = annotated_data_copy.values.tolist()\n",
    "# 0 = ANSWER   ,   1 = ID   ,   2 = QUESTION   ,   3 = DISTORTED PART   ,\n",
    "# 4 = DOMINANT DISTORTION   ,   5 = SECONDARY DISTORTION   ,   6 = DISTORTION 1/0\n",
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoscaMitrut\\.conda\\envs\\tfgpu\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\RoscaMitrut\\.conda\\envs\\tfgpu\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "questions = [' '.join((re.sub('[^a-zA-Z]', ' ',el[2].lower())).split()) for el in data_list]\n",
    "distortions = [el[6] for el in data_list]\n",
    "\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "#sbert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "questions_embeded = sbert_model.encode(questions)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(questions_embeded, distortions, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,073\n",
      "Trainable params: 115,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "\ttf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model = Sequential() \n",
    "model.add(tf.keras.layers.Dense(128, activation='relu',input_shape=(768,)))\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(), metrics=METRICS)\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 6s 25ms/step - loss: 0.6704 - accuracy: 0.6215 - precision: 0.6711 - recall: 0.8063 - val_loss: 0.6150 - val_accuracy: 0.6443 - val_precision: 0.6318 - val_recall: 0.9392\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6104 - accuracy: 0.6784 - precision: 0.6987 - recall: 0.8786 - val_loss: 0.6148 - val_accuracy: 0.6502 - val_precision: 0.7179 - val_recall: 0.6622\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.5970 - accuracy: 0.6981 - precision: 0.7243 - recall: 0.8563 - val_loss: 0.5956 - val_accuracy: 0.6700 - val_precision: 0.6748 - val_recall: 0.8412\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.5708 - accuracy: 0.7036 - precision: 0.7170 - recall: 0.8901 - val_loss: 0.5878 - val_accuracy: 0.6858 - val_precision: 0.7108 - val_recall: 0.7804\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.5747 - accuracy: 0.7036 - precision: 0.7326 - recall: 0.8486 - val_loss: 0.5972 - val_accuracy: 0.6739 - val_precision: 0.6737 - val_recall: 0.8581\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.5679 - accuracy: 0.7021 - precision: 0.7272 - recall: 0.8586 - val_loss: 0.5886 - val_accuracy: 0.6818 - val_precision: 0.6772 - val_recall: 0.8716\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.5633 - accuracy: 0.7125 - precision: 0.7367 - recall: 0.8601 - val_loss: 0.5820 - val_accuracy: 0.7036 - val_precision: 0.7281 - val_recall: 0.7872\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.5450 - accuracy: 0.7258 - precision: 0.7503 - recall: 0.8593 - val_loss: 0.5844 - val_accuracy: 0.7055 - val_precision: 0.7194 - val_recall: 0.8142\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.5427 - accuracy: 0.7208 - precision: 0.7447 - recall: 0.8609 - val_loss: 0.6131 - val_accuracy: 0.6522 - val_precision: 0.7479 - val_recall: 0.6115\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.5514 - accuracy: 0.7194 - precision: 0.7502 - recall: 0.8447 - val_loss: 0.5822 - val_accuracy: 0.6779 - val_precision: 0.6783 - val_recall: 0.8547\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.5317 - accuracy: 0.7292 - precision: 0.7546 - recall: 0.8578 - val_loss: 0.6195 - val_accuracy: 0.6621 - val_precision: 0.6450 - val_recall: 0.9392\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.5325 - accuracy: 0.7312 - precision: 0.7472 - recall: 0.8793 - val_loss: 0.6010 - val_accuracy: 0.6482 - val_precision: 0.6385 - val_recall: 0.9189\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.5292 - accuracy: 0.7204 - precision: 0.7345 - recall: 0.8847 - val_loss: 0.5923 - val_accuracy: 0.6719 - val_precision: 0.6776 - val_recall: 0.8378\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.5168 - accuracy: 0.7411 - precision: 0.7554 - recall: 0.8832 - val_loss: 0.5834 - val_accuracy: 0.6996 - val_precision: 0.6935 - val_recall: 0.8716\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.5051 - accuracy: 0.7451 - precision: 0.7713 - recall: 0.8578 - val_loss: 0.5926 - val_accuracy: 0.6996 - val_precision: 0.7069 - val_recall: 0.8311\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.4956 - accuracy: 0.7485 - precision: 0.7661 - recall: 0.8762 - val_loss: 0.5930 - val_accuracy: 0.6917 - val_precision: 0.6892 - val_recall: 0.8615\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.5023 - accuracy: 0.7500 - precision: 0.7603 - recall: 0.8924 - val_loss: 0.5849 - val_accuracy: 0.6976 - val_precision: 0.7037 - val_recall: 0.8345\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.4771 - accuracy: 0.7653 - precision: 0.7864 - recall: 0.8716 - val_loss: 0.6090 - val_accuracy: 0.6759 - val_precision: 0.6728 - val_recall: 0.8682\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.4918 - accuracy: 0.7465 - precision: 0.7627 - recall: 0.8793 - val_loss: 0.5950 - val_accuracy: 0.6937 - val_precision: 0.6841 - val_recall: 0.8851\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.4658 - accuracy: 0.7851 - precision: 0.7868 - recall: 0.9131 - val_loss: 0.5969 - val_accuracy: 0.7055 - val_precision: 0.7118 - val_recall: 0.8345\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distortions.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1597"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distortions.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoscaMitrut\\.conda\\envs\\tfgpu\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "questions = [el[2] for el in data_list]\n",
    "distortions = [el[6] for el in data_list]\n",
    "\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "#sbert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "questions_embeded = sbert_model.encode(questions)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(questions_embeded, distortions, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 1/euclidean:  0.6264822134387352\n",
      "acc 1/cosine:  0.6284584980237155\n",
      "acc 2/euclidean:  0.6067193675889329\n",
      "acc 2/cosine:  0.6007905138339921\n",
      "acc 3/euclidean:  0.6600790513833992\n",
      "acc 3/cosine:  0.6600790513833992\n",
      "acc 4/euclidean:  0.6403162055335968\n",
      "acc 4/cosine:  0.658102766798419\n",
      "acc 5/euclidean:  0.6798418972332015\n",
      "acc 5/cosine:  0.6640316205533597\n",
      "acc 6/euclidean:  0.6640316205533597\n",
      "acc 6/cosine:  0.66600790513834\n",
      "acc 7/euclidean:  0.658102766798419\n",
      "acc 7/cosine:  0.6640316205533597\n",
      "acc 8/euclidean:  0.6600790513833992\n",
      "acc 8/cosine:  0.6620553359683794\n",
      "acc 9/euclidean:  0.6699604743083004\n",
      "acc 9/cosine:  0.6699604743083004\n",
      "acc 10/euclidean:  0.6778656126482213\n",
      "acc 10/cosine:  0.6758893280632411\n",
      "acc 11/euclidean:  0.6679841897233202\n",
      "acc 11/cosine:  0.6699604743083004\n",
      "acc 12/euclidean:  0.66600790513834\n",
      "acc 12/cosine:  0.6600790513833992\n",
      "acc 13/euclidean:  0.6620553359683794\n",
      "acc 13/cosine:  0.6620553359683794\n",
      "acc 14/euclidean:  0.6640316205533597\n",
      "acc 14/cosine:  0.6600790513833992\n",
      "acc 15/euclidean:  0.66600790513834\n",
      "acc 15/cosine:  0.6620553359683794\n",
      "acc 16/euclidean:  0.6758893280632411\n",
      "acc 16/cosine:  0.6877470355731226\n",
      "acc 17/euclidean:  0.6699604743083004\n",
      "acc 17/cosine:  0.6699604743083004\n",
      "acc 18/euclidean:  0.6857707509881423\n",
      "acc 18/cosine:  0.6778656126482213\n",
      "acc 19/euclidean:  0.6679841897233202\n",
      "acc 19/cosine:  0.658102766798419\n",
      "acc 20/euclidean:  0.6778656126482213\n",
      "acc 20/cosine:  0.6758893280632411\n",
      "acc 21/euclidean:  0.6699604743083004\n",
      "acc 21/cosine:  0.658102766798419\n",
      "acc 22/euclidean:  0.6877470355731226\n",
      "acc 22/cosine:  0.6699604743083004\n",
      "acc 23/euclidean:  0.6719367588932806\n",
      "acc 23/cosine:  0.6719367588932806\n",
      "acc 24/euclidean:  0.6778656126482213\n",
      "acc 24/cosine:  0.6837944664031621\n",
      "acc 25/euclidean:  0.6699604743083004\n",
      "acc 25/cosine:  0.6719367588932806\n",
      "acc 26/euclidean:  0.6798418972332015\n",
      "acc 26/cosine:  0.6798418972332015\n",
      "acc 27/euclidean:  0.6699604743083004\n",
      "acc 27/cosine:  0.6778656126482213\n",
      "acc 28/euclidean:  0.6739130434782609\n",
      "acc 28/cosine:  0.6857707509881423\n",
      "acc 29/euclidean:  0.6640316205533597\n",
      "acc 29/cosine:  0.6818181818181818\n",
      "acc 30/euclidean:  0.6758893280632411\n",
      "acc 30/cosine:  0.6877470355731226\n",
      "acc 31/euclidean:  0.6620553359683794\n",
      "acc 31/cosine:  0.6798418972332015\n",
      "acc 32/euclidean:  0.6679841897233202\n",
      "acc 32/cosine:  0.6857707509881423\n",
      "acc 33/euclidean:  0.6719367588932806\n",
      "acc 33/cosine:  0.6837944664031621\n",
      "acc 34/euclidean:  0.6739130434782609\n",
      "acc 34/cosine:  0.6798418972332015\n",
      "acc 35/euclidean:  0.6640316205533597\n",
      "acc 35/cosine:  0.6739130434782609\n",
      "acc 36/euclidean:  0.6679841897233202\n",
      "acc 36/cosine:  0.6758893280632411\n",
      "acc 37/euclidean:  0.6679841897233202\n",
      "acc 37/cosine:  0.6719367588932806\n",
      "acc 38/euclidean:  0.6758893280632411\n",
      "acc 38/cosine:  0.6719367588932806\n",
      "acc 39/euclidean:  0.6699604743083004\n",
      "acc 39/cosine:  0.6640316205533597\n",
      "acc 40/euclidean:  0.6739130434782609\n",
      "acc 40/cosine:  0.6719367588932806\n",
      "acc 41/euclidean:  0.6620553359683794\n",
      "acc 41/cosine:  0.66600790513834\n",
      "acc 42/euclidean:  0.6719367588932806\n",
      "acc 42/cosine:  0.6679841897233202\n",
      "acc 43/euclidean:  0.66600790513834\n",
      "acc 43/cosine:  0.66600790513834\n",
      "acc 44/euclidean:  0.66600790513834\n",
      "acc 44/cosine:  0.66600790513834\n",
      "acc 45/euclidean:  0.6640316205533597\n",
      "acc 45/cosine:  0.6600790513833992\n",
      "acc 46/euclidean:  0.6699604743083004\n",
      "acc 46/cosine:  0.6620553359683794\n",
      "acc 47/euclidean:  0.6620553359683794\n",
      "acc 47/cosine:  0.6600790513833992\n",
      "acc 48/euclidean:  0.6739130434782609\n",
      "acc 48/cosine:  0.6600790513833992\n",
      "acc 49/euclidean:  0.6640316205533597\n",
      "acc 49/cosine:  0.6600790513833992\n",
      "acc 50/euclidean:  0.66600790513834\n",
      "acc 50/cosine:  0.66600790513834\n",
      "acc 51/euclidean:  0.6620553359683794\n",
      "acc 51/cosine:  0.6620553359683794\n",
      "acc 52/euclidean:  0.6679841897233202\n",
      "acc 52/cosine:  0.6640316205533597\n",
      "acc 53/euclidean:  0.6600790513833992\n",
      "acc 53/cosine:  0.6600790513833992\n",
      "acc 54/euclidean:  0.66600790513834\n",
      "acc 54/cosine:  0.6620553359683794\n",
      "acc 55/euclidean:  0.6541501976284585\n",
      "acc 55/cosine:  0.6600790513833992\n",
      "acc 56/euclidean:  0.66600790513834\n",
      "acc 56/cosine:  0.6620553359683794\n",
      "acc 57/euclidean:  0.6600790513833992\n",
      "acc 57/cosine:  0.6620553359683794\n",
      "acc 58/euclidean:  0.6679841897233202\n",
      "acc 58/cosine:  0.6620553359683794\n",
      "acc 59/euclidean:  0.6600790513833992\n",
      "acc 59/cosine:  0.6600790513833992\n",
      "acc 60/euclidean:  0.6699604743083004\n",
      "acc 60/cosine:  0.6561264822134387\n",
      "acc 61/euclidean:  0.6541501976284585\n",
      "acc 61/cosine:  0.6600790513833992\n",
      "acc 62/euclidean:  0.6620553359683794\n",
      "acc 62/cosine:  0.658102766798419\n",
      "acc 63/euclidean:  0.6541501976284585\n",
      "acc 63/cosine:  0.658102766798419\n",
      "acc 64/euclidean:  0.658102766798419\n",
      "acc 64/cosine:  0.6600790513833992\n",
      "acc 65/euclidean:  0.650197628458498\n",
      "acc 65/cosine:  0.6541501976284585\n",
      "acc 66/euclidean:  0.658102766798419\n",
      "acc 66/cosine:  0.658102766798419\n",
      "acc 67/euclidean:  0.6541501976284585\n",
      "acc 67/cosine:  0.658102766798419\n",
      "acc 68/euclidean:  0.658102766798419\n",
      "acc 68/cosine:  0.6600790513833992\n",
      "acc 69/euclidean:  0.6482213438735178\n",
      "acc 69/cosine:  0.658102766798419\n",
      "acc 70/euclidean:  0.6541501976284585\n",
      "acc 70/cosine:  0.6640316205533597\n",
      "acc 71/euclidean:  0.6462450592885376\n",
      "acc 71/cosine:  0.6620553359683794\n",
      "acc 72/euclidean:  0.6640316205533597\n",
      "acc 72/cosine:  0.66600790513834\n",
      "acc 73/euclidean:  0.6561264822134387\n",
      "acc 73/cosine:  0.6482213438735178\n",
      "acc 74/euclidean:  0.658102766798419\n",
      "acc 74/cosine:  0.6600790513833992\n",
      "acc 75/euclidean:  0.6462450592885376\n",
      "acc 75/cosine:  0.6521739130434783\n",
      "acc 76/euclidean:  0.6462450592885376\n",
      "acc 76/cosine:  0.658102766798419\n",
      "acc 77/euclidean:  0.6383399209486166\n",
      "acc 77/cosine:  0.6541501976284585\n",
      "acc 78/euclidean:  0.650197628458498\n",
      "acc 78/cosine:  0.6521739130434783\n",
      "acc 79/euclidean:  0.6442687747035574\n",
      "acc 79/cosine:  0.650197628458498\n",
      "acc 80/euclidean:  0.6482213438735178\n",
      "acc 80/cosine:  0.650197628458498\n",
      "acc 81/euclidean:  0.6482213438735178\n",
      "acc 81/cosine:  0.6462450592885376\n",
      "acc 82/euclidean:  0.6521739130434783\n",
      "acc 82/cosine:  0.6521739130434783\n",
      "acc 83/euclidean:  0.6462450592885376\n",
      "acc 83/cosine:  0.650197628458498\n",
      "acc 84/euclidean:  0.650197628458498\n",
      "acc 84/cosine:  0.6462450592885376\n",
      "acc 85/euclidean:  0.650197628458498\n",
      "acc 85/cosine:  0.642292490118577\n",
      "acc 86/euclidean:  0.6521739130434783\n",
      "acc 86/cosine:  0.6521739130434783\n",
      "acc 87/euclidean:  0.6442687747035574\n",
      "acc 87/cosine:  0.6462450592885376\n",
      "acc 88/euclidean:  0.650197628458498\n",
      "acc 88/cosine:  0.6521739130434783\n",
      "acc 89/euclidean:  0.6482213438735178\n",
      "acc 89/cosine:  0.6482213438735178\n",
      "acc 90/euclidean:  0.6482213438735178\n",
      "acc 90/cosine:  0.6462450592885376\n",
      "acc 91/euclidean:  0.6462450592885376\n",
      "acc 91/cosine:  0.6442687747035574\n",
      "acc 92/euclidean:  0.6462450592885376\n",
      "acc 92/cosine:  0.6482213438735178\n",
      "acc 93/euclidean:  0.642292490118577\n",
      "acc 93/cosine:  0.6462450592885376\n",
      "acc 94/euclidean:  0.642292490118577\n",
      "acc 94/cosine:  0.650197628458498\n",
      "acc 95/euclidean:  0.642292490118577\n",
      "acc 95/cosine:  0.6462450592885376\n",
      "acc 96/euclidean:  0.6383399209486166\n",
      "acc 96/cosine:  0.6442687747035574\n",
      "acc 97/euclidean:  0.6383399209486166\n",
      "acc 97/cosine:  0.6442687747035574\n",
      "acc 98/euclidean:  0.6403162055335968\n",
      "acc 98/cosine:  0.6442687747035574\n",
      "acc 99/euclidean:  0.6442687747035574\n",
      "acc 99/cosine:  0.6462450592885376\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "for i in range(1,100):\n",
    "\tclassifier = KNeighborsClassifier(n_neighbors=i, p=13, metric='euclidean')\n",
    "\tclassifier.fit(X_train,y_train)\n",
    "\tclassifiers.append(classifier)\n",
    "\tclassifier = KNeighborsClassifier(n_neighbors=i, p=13, metric='cosine')\n",
    "\tclassifier.fit(X_train,y_train)\n",
    "\tclassifiers.append(classifier)\n",
    " \n",
    "for model in classifiers:\n",
    "    pred = model.predict(X_test)\n",
    "    print(f\"acc {model.n_neighbors}/{model.metric}: \",accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 1/euclidean:  0.6245059288537549\n",
      "acc 1/cosine:  0.616600790513834\n",
      "acc 2/euclidean:  0.5790513833992095\n",
      "acc 2/cosine:  0.5830039525691699\n",
      "acc 3/euclidean:  0.6304347826086957\n",
      "acc 3/cosine:  0.6245059288537549\n",
      "acc 4/euclidean:  0.6245059288537549\n",
      "acc 4/cosine:  0.6284584980237155\n",
      "acc 5/euclidean:  0.6541501976284585\n",
      "acc 5/cosine:  0.6482213438735178\n",
      "acc 6/euclidean:  0.6403162055335968\n",
      "acc 6/cosine:  0.642292490118577\n",
      "acc 7/euclidean:  0.642292490118577\n",
      "acc 7/cosine:  0.6541501976284585\n",
      "acc 8/euclidean:  0.6442687747035574\n",
      "acc 8/cosine:  0.6561264822134387\n",
      "acc 9/euclidean:  0.6462450592885376\n",
      "acc 9/cosine:  0.6442687747035574\n",
      "acc 10/euclidean:  0.6363636363636364\n",
      "acc 10/cosine:  0.6462450592885376\n",
      "acc 11/euclidean:  0.6403162055335968\n",
      "acc 11/cosine:  0.6363636363636364\n",
      "acc 12/euclidean:  0.6343873517786561\n",
      "acc 12/cosine:  0.6343873517786561\n",
      "acc 13/euclidean:  0.6442687747035574\n",
      "acc 13/cosine:  0.6403162055335968\n",
      "acc 14/euclidean:  0.6462450592885376\n",
      "acc 14/cosine:  0.642292490118577\n",
      "acc 15/euclidean:  0.6462450592885376\n",
      "acc 15/cosine:  0.650197628458498\n",
      "acc 16/euclidean:  0.6482213438735178\n",
      "acc 16/cosine:  0.6541501976284585\n",
      "acc 17/euclidean:  0.642292490118577\n",
      "acc 17/cosine:  0.6482213438735178\n",
      "acc 18/euclidean:  0.6482213438735178\n",
      "acc 18/cosine:  0.6561264822134387\n",
      "acc 19/euclidean:  0.6482213438735178\n",
      "acc 19/cosine:  0.6561264822134387\n",
      "acc 20/euclidean:  0.6442687747035574\n",
      "acc 20/cosine:  0.658102766798419\n",
      "acc 21/euclidean:  0.6383399209486166\n",
      "acc 21/cosine:  0.6482213438735178\n",
      "acc 22/euclidean:  0.6442687747035574\n",
      "acc 22/cosine:  0.6719367588932806\n",
      "acc 23/euclidean:  0.642292490118577\n",
      "acc 23/cosine:  0.66600790513834\n",
      "acc 24/euclidean:  0.658102766798419\n",
      "acc 24/cosine:  0.6758893280632411\n",
      "acc 25/euclidean:  0.650197628458498\n",
      "acc 25/cosine:  0.6719367588932806\n",
      "acc 26/euclidean:  0.658102766798419\n",
      "acc 26/cosine:  0.6719367588932806\n",
      "acc 27/euclidean:  0.6620553359683794\n",
      "acc 27/cosine:  0.6620553359683794\n",
      "acc 28/euclidean:  0.6679841897233202\n",
      "acc 28/cosine:  0.6699604743083004\n",
      "acc 29/euclidean:  0.658102766798419\n",
      "acc 29/cosine:  0.6600790513833992\n",
      "acc 30/euclidean:  0.66600790513834\n",
      "acc 30/cosine:  0.6778656126482213\n",
      "acc 31/euclidean:  0.6521739130434783\n",
      "acc 31/cosine:  0.6600790513833992\n",
      "acc 32/euclidean:  0.66600790513834\n",
      "acc 32/cosine:  0.6719367588932806\n",
      "acc 33/euclidean:  0.6521739130434783\n",
      "acc 33/cosine:  0.6620553359683794\n",
      "acc 34/euclidean:  0.66600790513834\n",
      "acc 34/cosine:  0.6739130434782609\n",
      "acc 35/euclidean:  0.6561264822134387\n",
      "acc 35/cosine:  0.6561264822134387\n",
      "acc 36/euclidean:  0.6679841897233202\n",
      "acc 36/cosine:  0.6699604743083004\n",
      "acc 37/euclidean:  0.6600790513833992\n",
      "acc 37/cosine:  0.658102766798419\n",
      "acc 38/euclidean:  0.6600790513833992\n",
      "acc 38/cosine:  0.6640316205533597\n",
      "acc 39/euclidean:  0.6600790513833992\n",
      "acc 39/cosine:  0.658102766798419\n",
      "acc 40/euclidean:  0.658102766798419\n",
      "acc 40/cosine:  0.6620553359683794\n",
      "acc 41/euclidean:  0.658102766798419\n",
      "acc 41/cosine:  0.6600790513833992\n",
      "acc 42/euclidean:  0.6561264822134387\n",
      "acc 42/cosine:  0.6620553359683794\n",
      "acc 43/euclidean:  0.658102766798419\n",
      "acc 43/cosine:  0.6541501976284585\n",
      "acc 44/euclidean:  0.6561264822134387\n",
      "acc 44/cosine:  0.6620553359683794\n",
      "acc 45/euclidean:  0.6521739130434783\n",
      "acc 45/cosine:  0.6561264822134387\n",
      "acc 46/euclidean:  0.658102766798419\n",
      "acc 46/cosine:  0.66600790513834\n",
      "acc 47/euclidean:  0.6541501976284585\n",
      "acc 47/cosine:  0.6620553359683794\n",
      "acc 48/euclidean:  0.6600790513833992\n",
      "acc 48/cosine:  0.6699604743083004\n",
      "acc 49/euclidean:  0.6541501976284585\n",
      "acc 49/cosine:  0.66600790513834\n",
      "acc 50/euclidean:  0.658102766798419\n",
      "acc 50/cosine:  0.6739130434782609\n",
      "acc 51/euclidean:  0.6541501976284585\n",
      "acc 51/cosine:  0.6640316205533597\n",
      "acc 52/euclidean:  0.6600790513833992\n",
      "acc 52/cosine:  0.6699604743083004\n",
      "acc 53/euclidean:  0.6600790513833992\n",
      "acc 53/cosine:  0.6679841897233202\n",
      "acc 54/euclidean:  0.658102766798419\n",
      "acc 54/cosine:  0.6620553359683794\n",
      "acc 55/euclidean:  0.6620553359683794\n",
      "acc 55/cosine:  0.66600790513834\n",
      "acc 56/euclidean:  0.658102766798419\n",
      "acc 56/cosine:  0.6640316205533597\n",
      "acc 57/euclidean:  0.6600790513833992\n",
      "acc 57/cosine:  0.6600790513833992\n",
      "acc 58/euclidean:  0.6561264822134387\n",
      "acc 58/cosine:  0.658102766798419\n",
      "acc 59/euclidean:  0.6561264822134387\n",
      "acc 59/cosine:  0.658102766798419\n",
      "acc 60/euclidean:  0.6541501976284585\n",
      "acc 60/cosine:  0.6561264822134387\n",
      "acc 61/euclidean:  0.658102766798419\n",
      "acc 61/cosine:  0.6521739130434783\n",
      "acc 62/euclidean:  0.6561264822134387\n",
      "acc 62/cosine:  0.6541501976284585\n",
      "acc 63/euclidean:  0.658102766798419\n",
      "acc 63/cosine:  0.6541501976284585\n",
      "acc 64/euclidean:  0.658102766798419\n",
      "acc 64/cosine:  0.6561264822134387\n",
      "acc 65/euclidean:  0.658102766798419\n",
      "acc 65/cosine:  0.6521739130434783\n",
      "acc 66/euclidean:  0.6541501976284585\n",
      "acc 66/cosine:  0.6541501976284585\n",
      "acc 67/euclidean:  0.6600790513833992\n",
      "acc 67/cosine:  0.6561264822134387\n",
      "acc 68/euclidean:  0.6561264822134387\n",
      "acc 68/cosine:  0.6541501976284585\n",
      "acc 69/euclidean:  0.658102766798419\n",
      "acc 69/cosine:  0.6482213438735178\n",
      "acc 70/euclidean:  0.6541501976284585\n",
      "acc 70/cosine:  0.6482213438735178\n",
      "acc 71/euclidean:  0.6541501976284585\n",
      "acc 71/cosine:  0.6482213438735178\n",
      "acc 72/euclidean:  0.6561264822134387\n",
      "acc 72/cosine:  0.6521739130434783\n",
      "acc 73/euclidean:  0.658102766798419\n",
      "acc 73/cosine:  0.650197628458498\n",
      "acc 74/euclidean:  0.6600790513833992\n",
      "acc 74/cosine:  0.6521739130434783\n",
      "acc 75/euclidean:  0.6561264822134387\n",
      "acc 75/cosine:  0.650197628458498\n",
      "acc 76/euclidean:  0.6541501976284585\n",
      "acc 76/cosine:  0.658102766798419\n",
      "acc 77/euclidean:  0.6561264822134387\n",
      "acc 77/cosine:  0.6541501976284585\n",
      "acc 78/euclidean:  0.658102766798419\n",
      "acc 78/cosine:  0.6561264822134387\n",
      "acc 79/euclidean:  0.650197628458498\n",
      "acc 79/cosine:  0.650197628458498\n",
      "acc 80/euclidean:  0.6521739130434783\n",
      "acc 80/cosine:  0.6561264822134387\n",
      "acc 81/euclidean:  0.6462450592885376\n",
      "acc 81/cosine:  0.650197628458498\n",
      "acc 82/euclidean:  0.650197628458498\n",
      "acc 82/cosine:  0.6561264822134387\n",
      "acc 83/euclidean:  0.6462450592885376\n",
      "acc 83/cosine:  0.650197628458498\n",
      "acc 84/euclidean:  0.6521739130434783\n",
      "acc 84/cosine:  0.6521739130434783\n",
      "acc 85/euclidean:  0.6462450592885376\n",
      "acc 85/cosine:  0.6482213438735178\n",
      "acc 86/euclidean:  0.6442687747035574\n",
      "acc 86/cosine:  0.6521739130434783\n",
      "acc 87/euclidean:  0.6462450592885376\n",
      "acc 87/cosine:  0.650197628458498\n",
      "acc 88/euclidean:  0.6482213438735178\n",
      "acc 88/cosine:  0.6561264822134387\n",
      "acc 89/euclidean:  0.650197628458498\n",
      "acc 89/cosine:  0.6541501976284585\n",
      "acc 90/euclidean:  0.650197628458498\n",
      "acc 90/cosine:  0.6521739130434783\n",
      "acc 91/euclidean:  0.6462450592885376\n",
      "acc 91/cosine:  0.6521739130434783\n",
      "acc 92/euclidean:  0.6482213438735178\n",
      "acc 92/cosine:  0.6521739130434783\n",
      "acc 93/euclidean:  0.6482213438735178\n",
      "acc 93/cosine:  0.6541501976284585\n",
      "acc 94/euclidean:  0.6462450592885376\n",
      "acc 94/cosine:  0.658102766798419\n",
      "acc 95/euclidean:  0.6442687747035574\n",
      "acc 95/cosine:  0.6541501976284585\n",
      "acc 96/euclidean:  0.6442687747035574\n",
      "acc 96/cosine:  0.6521739130434783\n",
      "acc 97/euclidean:  0.6403162055335968\n",
      "acc 97/cosine:  0.6482213438735178\n",
      "acc 98/euclidean:  0.6403162055335968\n",
      "acc 98/cosine:  0.650197628458498\n",
      "acc 99/euclidean:  0.6403162055335968\n",
      "acc 99/cosine:  0.650197628458498\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "for i in range(1,100):\n",
    "\tclassifier = KNeighborsClassifier(n_neighbors=i, p=13, metric='euclidean')\n",
    "\tclassifier.fit(X_train,y_train)\n",
    "\tclassifiers.append(classifier)\n",
    "\tclassifier = KNeighborsClassifier(n_neighbors=i, p=13, metric='cosine')\n",
    "\tclassifier.fit(X_train,y_train)\n",
    "\tclassifiers.append(classifier)\n",
    " \n",
    "for model in classifiers:\n",
    "    pred = model.predict(X_test)\n",
    "    print(f\"acc {model.n_neighbors}/{model.metric}: \",accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoscaMitrut\\.conda\\envs\\tfgpu\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(text):\n",
    "    text = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in text if word.isalpha() and not word in stop_words]\n",
    "    return ' '.join(text)\n",
    "\n",
    "texts = [el[2] for el in data_list]\n",
    "\n",
    "distortions = [el[6] for el in data_list]\n",
    "questions = list(map(remove_stop_words,texts))\n",
    "\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "#sbert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "questions_embeded = sbert_model.encode(questions)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(questions_embeded, distortions, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 1/euclidean:  0.6640316205533597\n",
      "acc 1/cosine:  0.6719367588932806\n",
      "acc 2/euclidean:  0.6225296442687747\n",
      "acc 2/cosine:  0.6245059288537549\n",
      "acc 3/euclidean:  0.6699604743083004\n",
      "acc 3/cosine:  0.6778656126482213\n",
      "acc 4/euclidean:  0.6818181818181818\n",
      "acc 4/cosine:  0.6877470355731226\n",
      "acc 5/euclidean:  0.6719367588932806\n",
      "acc 5/cosine:  0.6719367588932806\n",
      "acc 6/euclidean:  0.6956521739130435\n",
      "acc 6/cosine:  0.6857707509881423\n",
      "acc 7/euclidean:  0.6818181818181818\n",
      "acc 7/cosine:  0.6778656126482213\n",
      "acc 8/euclidean:  0.7015810276679841\n",
      "acc 8/cosine:  0.6818181818181818\n",
      "acc 9/euclidean:  0.6679841897233202\n",
      "acc 9/cosine:  0.6620553359683794\n",
      "acc 10/euclidean:  0.66600790513834\n",
      "acc 10/cosine:  0.6798418972332015\n",
      "acc 11/euclidean:  0.66600790513834\n",
      "acc 11/cosine:  0.6620553359683794\n",
      "acc 12/euclidean:  0.6837944664031621\n",
      "acc 12/cosine:  0.6837944664031621\n",
      "acc 13/euclidean:  0.6699604743083004\n",
      "acc 13/cosine:  0.6778656126482213\n",
      "acc 14/euclidean:  0.6818181818181818\n",
      "acc 14/cosine:  0.6778656126482213\n",
      "acc 15/euclidean:  0.6640316205533597\n",
      "acc 15/cosine:  0.6679841897233202\n",
      "acc 16/euclidean:  0.6640316205533597\n",
      "acc 16/cosine:  0.6758893280632411\n",
      "acc 17/euclidean:  0.6561264822134387\n",
      "acc 17/cosine:  0.6561264822134387\n",
      "acc 18/euclidean:  0.6640316205533597\n",
      "acc 18/cosine:  0.6699604743083004\n",
      "acc 19/euclidean:  0.6600790513833992\n",
      "acc 19/cosine:  0.6561264822134387\n",
      "acc 20/euclidean:  0.6679841897233202\n",
      "acc 20/cosine:  0.6640316205533597\n",
      "acc 21/euclidean:  0.6521739130434783\n",
      "acc 21/cosine:  0.6541501976284585\n",
      "acc 22/euclidean:  0.6640316205533597\n",
      "acc 22/cosine:  0.6600790513833992\n",
      "acc 23/euclidean:  0.6541501976284585\n",
      "acc 23/cosine:  0.6521739130434783\n",
      "acc 24/euclidean:  0.6561264822134387\n",
      "acc 24/cosine:  0.6600790513833992\n",
      "acc 25/euclidean:  0.6482213438735178\n",
      "acc 25/cosine:  0.658102766798419\n",
      "acc 26/euclidean:  0.6482213438735178\n",
      "acc 26/cosine:  0.6561264822134387\n",
      "acc 27/euclidean:  0.6521739130434783\n",
      "acc 27/cosine:  0.6561264822134387\n",
      "acc 28/euclidean:  0.6541501976284585\n",
      "acc 28/cosine:  0.658102766798419\n",
      "acc 29/euclidean:  0.6541501976284585\n",
      "acc 29/cosine:  0.6600790513833992\n",
      "acc 30/euclidean:  0.658102766798419\n",
      "acc 30/cosine:  0.6620553359683794\n",
      "acc 31/euclidean:  0.6561264822134387\n",
      "acc 31/cosine:  0.658102766798419\n",
      "acc 32/euclidean:  0.658102766798419\n",
      "acc 32/cosine:  0.6541501976284585\n",
      "acc 33/euclidean:  0.6600790513833992\n",
      "acc 33/cosine:  0.658102766798419\n",
      "acc 34/euclidean:  0.6600790513833992\n",
      "acc 34/cosine:  0.6561264822134387\n",
      "acc 35/euclidean:  0.6561264822134387\n",
      "acc 35/cosine:  0.658102766798419\n",
      "acc 36/euclidean:  0.6561264822134387\n",
      "acc 36/cosine:  0.6600790513833992\n",
      "acc 37/euclidean:  0.6561264822134387\n",
      "acc 37/cosine:  0.6521739130434783\n",
      "acc 38/euclidean:  0.6541501976284585\n",
      "acc 38/cosine:  0.6561264822134387\n",
      "acc 39/euclidean:  0.650197628458498\n",
      "acc 39/cosine:  0.6561264822134387\n",
      "acc 40/euclidean:  0.6561264822134387\n",
      "acc 40/cosine:  0.6561264822134387\n",
      "acc 41/euclidean:  0.650197628458498\n",
      "acc 41/cosine:  0.6541501976284585\n",
      "acc 42/euclidean:  0.650197628458498\n",
      "acc 42/cosine:  0.658102766798419\n",
      "acc 43/euclidean:  0.650197628458498\n",
      "acc 43/cosine:  0.6521739130434783\n",
      "acc 44/euclidean:  0.6482213438735178\n",
      "acc 44/cosine:  0.650197628458498\n",
      "acc 45/euclidean:  0.6521739130434783\n",
      "acc 45/cosine:  0.6521739130434783\n",
      "acc 46/euclidean:  0.6521739130434783\n",
      "acc 46/cosine:  0.650197628458498\n",
      "acc 47/euclidean:  0.6521739130434783\n",
      "acc 47/cosine:  0.650197628458498\n",
      "acc 48/euclidean:  0.6521739130434783\n",
      "acc 48/cosine:  0.6462450592885376\n",
      "acc 49/euclidean:  0.6521739130434783\n",
      "acc 49/cosine:  0.6462450592885376\n",
      "acc 50/euclidean:  0.6482213438735178\n",
      "acc 50/cosine:  0.6442687747035574\n",
      "acc 51/euclidean:  0.6521739130434783\n",
      "acc 51/cosine:  0.6482213438735178\n",
      "acc 52/euclidean:  0.650197628458498\n",
      "acc 52/cosine:  0.6462450592885376\n",
      "acc 53/euclidean:  0.650197628458498\n",
      "acc 53/cosine:  0.6521739130434783\n",
      "acc 54/euclidean:  0.650197628458498\n",
      "acc 54/cosine:  0.650197628458498\n",
      "acc 55/euclidean:  0.650197628458498\n",
      "acc 55/cosine:  0.6482213438735178\n",
      "acc 56/euclidean:  0.6521739130434783\n",
      "acc 56/cosine:  0.650197628458498\n",
      "acc 57/euclidean:  0.6541501976284585\n",
      "acc 57/cosine:  0.650197628458498\n",
      "acc 58/euclidean:  0.6521739130434783\n",
      "acc 58/cosine:  0.6541501976284585\n",
      "acc 59/euclidean:  0.650197628458498\n",
      "acc 59/cosine:  0.650197628458498\n",
      "acc 60/euclidean:  0.650197628458498\n",
      "acc 60/cosine:  0.6521739130434783\n",
      "acc 61/euclidean:  0.6482213438735178\n",
      "acc 61/cosine:  0.6541501976284585\n",
      "acc 62/euclidean:  0.6462450592885376\n",
      "acc 62/cosine:  0.6521739130434783\n",
      "acc 63/euclidean:  0.650197628458498\n",
      "acc 63/cosine:  0.650197628458498\n",
      "acc 64/euclidean:  0.6521739130434783\n",
      "acc 64/cosine:  0.6482213438735178\n",
      "acc 65/euclidean:  0.650197628458498\n",
      "acc 65/cosine:  0.6462450592885376\n",
      "acc 66/euclidean:  0.6482213438735178\n",
      "acc 66/cosine:  0.6462450592885376\n",
      "acc 67/euclidean:  0.6482213438735178\n",
      "acc 67/cosine:  0.6462450592885376\n",
      "acc 68/euclidean:  0.6482213438735178\n",
      "acc 68/cosine:  0.6482213438735178\n",
      "acc 69/euclidean:  0.6482213438735178\n",
      "acc 69/cosine:  0.6442687747035574\n",
      "acc 70/euclidean:  0.650197628458498\n",
      "acc 70/cosine:  0.642292490118577\n",
      "acc 71/euclidean:  0.6521739130434783\n",
      "acc 71/cosine:  0.6462450592885376\n",
      "acc 72/euclidean:  0.650197628458498\n",
      "acc 72/cosine:  0.6442687747035574\n",
      "acc 73/euclidean:  0.6462450592885376\n",
      "acc 73/cosine:  0.6442687747035574\n",
      "acc 74/euclidean:  0.6442687747035574\n",
      "acc 74/cosine:  0.6462450592885376\n",
      "acc 75/euclidean:  0.650197628458498\n",
      "acc 75/cosine:  0.642292490118577\n",
      "acc 76/euclidean:  0.6482213438735178\n",
      "acc 76/cosine:  0.6462450592885376\n",
      "acc 77/euclidean:  0.650197628458498\n",
      "acc 77/cosine:  0.642292490118577\n",
      "acc 78/euclidean:  0.650197628458498\n",
      "acc 78/cosine:  0.642292490118577\n",
      "acc 79/euclidean:  0.6462450592885376\n",
      "acc 79/cosine:  0.6442687747035574\n",
      "acc 80/euclidean:  0.6462450592885376\n",
      "acc 80/cosine:  0.642292490118577\n",
      "acc 81/euclidean:  0.6462450592885376\n",
      "acc 81/cosine:  0.6442687747035574\n",
      "acc 82/euclidean:  0.6462450592885376\n",
      "acc 82/cosine:  0.6403162055335968\n",
      "acc 83/euclidean:  0.6462450592885376\n",
      "acc 83/cosine:  0.6442687747035574\n",
      "acc 84/euclidean:  0.6462450592885376\n",
      "acc 84/cosine:  0.6462450592885376\n",
      "acc 85/euclidean:  0.6462450592885376\n",
      "acc 85/cosine:  0.6442687747035574\n",
      "acc 86/euclidean:  0.6442687747035574\n",
      "acc 86/cosine:  0.6462450592885376\n",
      "acc 87/euclidean:  0.6462450592885376\n",
      "acc 87/cosine:  0.6462450592885376\n",
      "acc 88/euclidean:  0.6442687747035574\n",
      "acc 88/cosine:  0.6462450592885376\n",
      "acc 89/euclidean:  0.6442687747035574\n",
      "acc 89/cosine:  0.6482213438735178\n",
      "acc 90/euclidean:  0.6442687747035574\n",
      "acc 90/cosine:  0.6482213438735178\n",
      "acc 91/euclidean:  0.6462450592885376\n",
      "acc 91/cosine:  0.6462450592885376\n",
      "acc 92/euclidean:  0.6462450592885376\n",
      "acc 92/cosine:  0.6482213438735178\n",
      "acc 93/euclidean:  0.6462450592885376\n",
      "acc 93/cosine:  0.6482213438735178\n",
      "acc 94/euclidean:  0.6482213438735178\n",
      "acc 94/cosine:  0.6482213438735178\n",
      "acc 95/euclidean:  0.6482213438735178\n",
      "acc 95/cosine:  0.650197628458498\n",
      "acc 96/euclidean:  0.6482213438735178\n",
      "acc 96/cosine:  0.650197628458498\n",
      "acc 97/euclidean:  0.6482213438735178\n",
      "acc 97/cosine:  0.650197628458498\n",
      "acc 98/euclidean:  0.6482213438735178\n",
      "acc 98/cosine:  0.6521739130434783\n",
      "acc 99/euclidean:  0.6482213438735178\n",
      "acc 99/cosine:  0.650197628458498\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "for i in range(1,100):\n",
    "\tclassifier = KNeighborsClassifier(n_neighbors=i, p=13, metric='euclidean')\n",
    "\tclassifier.fit(X_train,y_train)\n",
    "\tclassifiers.append(classifier)\n",
    "\tclassifier = KNeighborsClassifier(n_neighbors=i, p=13, metric='cosine')\n",
    "\tclassifier.fit(X_train,y_train)\n",
    "\tclassifiers.append(classifier)\n",
    " \n",
    "for model in classifiers:\n",
    "    pred = model.predict(X_test)\n",
    "    print(f\"acc {model.n_neighbors}/{model.metric}: \",accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4849271 ],\n",
       "       [0.52953875],\n",
       "       [0.8346922 ],\n",
       "       [0.62169254],\n",
       "       [0.7272236 ],\n",
       "       [0.7676399 ],\n",
       "       [0.96699345],\n",
       "       [0.6933755 ],\n",
       "       [0.6765701 ],\n",
       "       [0.8144874 ],\n",
       "       [0.45595375],\n",
       "       [0.728874  ],\n",
       "       [0.7913272 ],\n",
       "       [0.9781425 ],\n",
       "       [0.78560567],\n",
       "       [0.5860719 ],\n",
       "       [0.96007365],\n",
       "       [0.7512484 ],\n",
       "       [0.89301556],\n",
       "       [0.62584496],\n",
       "       [0.8760661 ],\n",
       "       [0.00391083],\n",
       "       [0.55173826],\n",
       "       [0.9548556 ],\n",
       "       [0.8965072 ],\n",
       "       [0.8040059 ],\n",
       "       [0.6184691 ],\n",
       "       [0.77206016],\n",
       "       [0.71879756],\n",
       "       [0.9488163 ],\n",
       "       [0.44598526],\n",
       "       [0.63923395],\n",
       "       [0.60754454],\n",
       "       [0.24079126],\n",
       "       [0.5175791 ],\n",
       "       [0.85308504],\n",
       "       [0.5913644 ],\n",
       "       [0.9240685 ],\n",
       "       [0.25043783],\n",
       "       [0.99402255],\n",
       "       [0.9916551 ],\n",
       "       [0.37664092],\n",
       "       [0.93840325],\n",
       "       [0.9803491 ],\n",
       "       [0.7134445 ],\n",
       "       [0.14731732],\n",
       "       [0.00482014],\n",
       "       [0.49537238],\n",
       "       [0.92865723],\n",
       "       [0.9287361 ],\n",
       "       [0.8058376 ],\n",
       "       [0.55510855],\n",
       "       [0.6253945 ],\n",
       "       [0.20550527],\n",
       "       [0.63443995],\n",
       "       [0.77849305],\n",
       "       [0.4426778 ],\n",
       "       [0.8334472 ],\n",
       "       [0.65343493],\n",
       "       [0.35434368],\n",
       "       [0.98047906],\n",
       "       [0.49691647],\n",
       "       [0.6422725 ],\n",
       "       [0.7107532 ],\n",
       "       [0.8749532 ],\n",
       "       [0.85364175],\n",
       "       [0.1297899 ],\n",
       "       [0.6059662 ],\n",
       "       [0.4736673 ],\n",
       "       [0.5727506 ],\n",
       "       [0.8954352 ],\n",
       "       [0.8891788 ],\n",
       "       [0.6002953 ],\n",
       "       [0.14898   ],\n",
       "       [0.39231178],\n",
       "       [0.61986935],\n",
       "       [0.9645085 ],\n",
       "       [0.52897257],\n",
       "       [0.51290894],\n",
       "       [0.93603855],\n",
       "       [0.89293545],\n",
       "       [0.7025906 ],\n",
       "       [0.3686811 ],\n",
       "       [0.60766953],\n",
       "       [0.5590668 ],\n",
       "       [0.6556568 ],\n",
       "       [0.3602715 ],\n",
       "       [0.52948976],\n",
       "       [0.52342117],\n",
       "       [0.8466213 ],\n",
       "       [0.75430894],\n",
       "       [0.8237408 ],\n",
       "       [0.19819959],\n",
       "       [0.8589341 ],\n",
       "       [0.6798074 ],\n",
       "       [0.41910803],\n",
       "       [0.6835105 ],\n",
       "       [0.5150699 ],\n",
       "       [0.9880332 ],\n",
       "       [0.91346544],\n",
       "       [0.8068459 ],\n",
       "       [0.5294569 ],\n",
       "       [0.70614517],\n",
       "       [0.27379224],\n",
       "       [0.41574976],\n",
       "       [0.32679906],\n",
       "       [0.09773425],\n",
       "       [0.81588286],\n",
       "       [0.74158233],\n",
       "       [0.546051  ],\n",
       "       [0.00365909],\n",
       "       [0.11298826],\n",
       "       [0.35004744],\n",
       "       [0.9700089 ],\n",
       "       [0.25254908],\n",
       "       [0.9527148 ],\n",
       "       [0.4514624 ],\n",
       "       [0.9445351 ],\n",
       "       [0.6730518 ],\n",
       "       [0.0582679 ],\n",
       "       [0.38171872],\n",
       "       [0.79398245],\n",
       "       [0.26676342],\n",
       "       [0.9564259 ],\n",
       "       [0.47983763],\n",
       "       [0.92151874],\n",
       "       [0.5733045 ],\n",
       "       [0.5948616 ],\n",
       "       [0.8371592 ],\n",
       "       [0.23568887],\n",
       "       [0.07532884],\n",
       "       [0.54515827],\n",
       "       [0.48701245],\n",
       "       [0.34146866],\n",
       "       [0.76964587],\n",
       "       [0.9851673 ],\n",
       "       [0.2418028 ],\n",
       "       [0.958577  ],\n",
       "       [0.80534965],\n",
       "       [0.8704424 ],\n",
       "       [0.54651207],\n",
       "       [0.33445403],\n",
       "       [0.37080172],\n",
       "       [0.8678549 ],\n",
       "       [0.63791263],\n",
       "       [0.79248285],\n",
       "       [0.7521473 ],\n",
       "       [0.49428573],\n",
       "       [0.06336617],\n",
       "       [0.88131183],\n",
       "       [0.71698636],\n",
       "       [0.07159519],\n",
       "       [0.7648748 ],\n",
       "       [0.90285486],\n",
       "       [0.84181184],\n",
       "       [0.87867147],\n",
       "       [0.8165864 ],\n",
       "       [0.6849878 ],\n",
       "       [0.22797231],\n",
       "       [0.80583215],\n",
       "       [0.06534742],\n",
       "       [0.37609643],\n",
       "       [0.906801  ],\n",
       "       [0.35741997],\n",
       "       [0.47651997],\n",
       "       [0.9035068 ],\n",
       "       [0.8488481 ],\n",
       "       [0.42739195],\n",
       "       [0.98314536],\n",
       "       [0.9846475 ],\n",
       "       [0.98364484],\n",
       "       [0.5954616 ],\n",
       "       [0.7542183 ],\n",
       "       [0.4393048 ],\n",
       "       [0.85033745],\n",
       "       [0.9851126 ],\n",
       "       [0.37996063],\n",
       "       [0.5423055 ],\n",
       "       [0.67847157],\n",
       "       [0.68788725],\n",
       "       [0.9846762 ],\n",
       "       [0.7220134 ],\n",
       "       [0.18879229],\n",
       "       [0.73541206],\n",
       "       [0.77113223],\n",
       "       [0.3887    ],\n",
       "       [0.11961786],\n",
       "       [0.98314536],\n",
       "       [0.93727076],\n",
       "       [0.01542693],\n",
       "       [0.49133202],\n",
       "       [0.7821186 ],\n",
       "       [0.6702783 ],\n",
       "       [0.8195022 ],\n",
       "       [0.61188185],\n",
       "       [0.7479703 ],\n",
       "       [0.37830207],\n",
       "       [0.8686591 ],\n",
       "       [0.40052998],\n",
       "       [0.41557997],\n",
       "       [0.9791437 ],\n",
       "       [0.5892721 ],\n",
       "       [0.8822013 ],\n",
       "       [0.32287788],\n",
       "       [0.95370185],\n",
       "       [0.8758205 ],\n",
       "       [0.21752203],\n",
       "       [0.39980045],\n",
       "       [0.8520272 ],\n",
       "       [0.64049387],\n",
       "       [0.70674354],\n",
       "       [0.44086018],\n",
       "       [0.20448154],\n",
       "       [0.58145976],\n",
       "       [0.75922793],\n",
       "       [0.5372259 ],\n",
       "       [0.9779024 ],\n",
       "       [0.9122407 ],\n",
       "       [0.8239306 ],\n",
       "       [0.7675234 ],\n",
       "       [0.5527697 ],\n",
       "       [0.47339132],\n",
       "       [0.8476077 ],\n",
       "       [0.8154992 ],\n",
       "       [0.84664184],\n",
       "       [0.8349225 ],\n",
       "       [0.282254  ],\n",
       "       [0.57332003],\n",
       "       [0.23860388],\n",
       "       [0.23677413],\n",
       "       [0.50662345],\n",
       "       [0.8067208 ],\n",
       "       [0.44361553],\n",
       "       [0.50884384],\n",
       "       [0.92475367],\n",
       "       [0.8097121 ],\n",
       "       [0.1838019 ],\n",
       "       [0.61734533],\n",
       "       [0.23097646],\n",
       "       [0.9435502 ],\n",
       "       [0.7228652 ],\n",
       "       [0.8176868 ],\n",
       "       [0.50535864],\n",
       "       [0.99063   ],\n",
       "       [0.32797214],\n",
       "       [0.53522444],\n",
       "       [0.697986  ],\n",
       "       [0.63072366],\n",
       "       [0.34248638],\n",
       "       [0.6148859 ],\n",
       "       [0.55727416],\n",
       "       [0.6355091 ],\n",
       "       [0.5075873 ],\n",
       "       [0.4680791 ],\n",
       "       [0.8559374 ],\n",
       "       [0.6191162 ],\n",
       "       [0.9308429 ],\n",
       "       [0.4170855 ],\n",
       "       [0.9779508 ],\n",
       "       [0.79837507],\n",
       "       [0.47488937],\n",
       "       [0.75311786],\n",
       "       [0.5863492 ],\n",
       "       [0.84535044],\n",
       "       [0.68156856],\n",
       "       [0.84918547],\n",
       "       [0.606505  ],\n",
       "       [0.5707236 ],\n",
       "       [0.92245007],\n",
       "       [0.6881314 ],\n",
       "       [0.45551947],\n",
       "       [0.6785195 ],\n",
       "       [0.25587714],\n",
       "       [0.41818488],\n",
       "       [0.6807181 ],\n",
       "       [0.1979996 ],\n",
       "       [0.7490119 ],\n",
       "       [0.5474567 ],\n",
       "       [0.18373165],\n",
       "       [0.79992735],\n",
       "       [0.05063085],\n",
       "       [0.8274812 ],\n",
       "       [0.4847475 ],\n",
       "       [0.533927  ],\n",
       "       [0.52796155],\n",
       "       [0.69566923],\n",
       "       [0.28967887],\n",
       "       [0.9736198 ],\n",
       "       [0.44789317],\n",
       "       [0.6651172 ],\n",
       "       [0.66812134],\n",
       "       [0.34367818],\n",
       "       [0.06239821],\n",
       "       [0.8063046 ],\n",
       "       [0.9758202 ],\n",
       "       [0.8508158 ],\n",
       "       [0.29923546],\n",
       "       [0.8754302 ],\n",
       "       [0.9968569 ],\n",
       "       [0.67702264],\n",
       "       [0.942622  ],\n",
       "       [0.8375492 ],\n",
       "       [0.8942551 ],\n",
       "       [0.99770457],\n",
       "       [0.64859873],\n",
       "       [0.45391887],\n",
       "       [0.8193889 ],\n",
       "       [0.6064199 ],\n",
       "       [0.7162241 ],\n",
       "       [0.5209195 ],\n",
       "       [0.43201518],\n",
       "       [0.37280574],\n",
       "       [0.6708967 ],\n",
       "       [0.69050246],\n",
       "       [0.41299972],\n",
       "       [0.09018963],\n",
       "       [0.65207464],\n",
       "       [0.74701804],\n",
       "       [0.27732792],\n",
       "       [0.7420407 ],\n",
       "       [0.9490782 ],\n",
       "       [0.9089923 ],\n",
       "       [0.863135  ],\n",
       "       [0.82831156],\n",
       "       [0.9520484 ],\n",
       "       [0.306695  ],\n",
       "       [0.8666954 ],\n",
       "       [0.9842159 ],\n",
       "       [0.42911404],\n",
       "       [0.82029605],\n",
       "       [0.8036564 ],\n",
       "       [0.5089066 ],\n",
       "       [0.5356073 ],\n",
       "       [0.818425  ],\n",
       "       [0.9466292 ],\n",
       "       [0.5268067 ],\n",
       "       [0.6765181 ],\n",
       "       [0.08614889],\n",
       "       [0.03532628],\n",
       "       [0.86468923],\n",
       "       [0.9322793 ],\n",
       "       [0.7483437 ],\n",
       "       [0.9887687 ],\n",
       "       [0.6114747 ],\n",
       "       [0.29781675],\n",
       "       [0.09080026],\n",
       "       [0.6159753 ],\n",
       "       [0.60678965],\n",
       "       [0.60738087],\n",
       "       [0.55404156],\n",
       "       [0.5917106 ],\n",
       "       [0.9816232 ],\n",
       "       [0.351697  ],\n",
       "       [0.70064044],\n",
       "       [0.7516252 ],\n",
       "       [0.41222855],\n",
       "       [0.5013823 ],\n",
       "       [0.7706955 ],\n",
       "       [0.9410996 ],\n",
       "       [0.58554655],\n",
       "       [0.852895  ],\n",
       "       [0.91721576],\n",
       "       [0.65789485],\n",
       "       [0.91409165],\n",
       "       [0.05963999],\n",
       "       [0.9042345 ],\n",
       "       [0.26719877],\n",
       "       [0.61729723],\n",
       "       [0.0177769 ],\n",
       "       [0.04811966],\n",
       "       [0.26970452],\n",
       "       [0.7960378 ],\n",
       "       [0.00563182],\n",
       "       [0.5073651 ],\n",
       "       [0.7266465 ],\n",
       "       [0.83666325],\n",
       "       [0.5260826 ],\n",
       "       [0.9971207 ],\n",
       "       [0.51736313],\n",
       "       [0.8974507 ],\n",
       "       [0.6409812 ],\n",
       "       [0.7708423 ],\n",
       "       [0.7705583 ],\n",
       "       [0.4360306 ],\n",
       "       [0.9669815 ],\n",
       "       [0.67161494],\n",
       "       [0.05994858],\n",
       "       [0.24089944],\n",
       "       [0.597942  ],\n",
       "       [0.35890532],\n",
       "       [0.01638824],\n",
       "       [0.49147618],\n",
       "       [0.64116865],\n",
       "       [0.77664465],\n",
       "       [0.6928367 ],\n",
       "       [0.8941252 ],\n",
       "       [0.62422794],\n",
       "       [0.7740837 ],\n",
       "       [0.24840373],\n",
       "       [0.19319877],\n",
       "       [0.6598567 ],\n",
       "       [0.5825001 ],\n",
       "       [0.5966592 ],\n",
       "       [0.46542913],\n",
       "       [0.64165413],\n",
       "       [0.6143328 ],\n",
       "       [0.41604117],\n",
       "       [0.71446997],\n",
       "       [0.85784894],\n",
       "       [0.2941369 ],\n",
       "       [0.60218054],\n",
       "       [0.23239721],\n",
       "       [0.02623418],\n",
       "       [0.2858052 ],\n",
       "       [0.94508654],\n",
       "       [0.4287228 ],\n",
       "       [0.7545797 ],\n",
       "       [0.18023248],\n",
       "       [0.64311993],\n",
       "       [0.20570745],\n",
       "       [0.74491733],\n",
       "       [0.07731168],\n",
       "       [0.7743092 ],\n",
       "       [0.9318965 ],\n",
       "       [0.44588655],\n",
       "       [0.30064684],\n",
       "       [0.6331629 ],\n",
       "       [0.56184375],\n",
       "       [0.48535746],\n",
       "       [0.8221601 ],\n",
       "       [0.37522092],\n",
       "       [0.60315984],\n",
       "       [0.4643794 ],\n",
       "       [0.93368566],\n",
       "       [0.7599676 ],\n",
       "       [0.70376307],\n",
       "       [0.84787273],\n",
       "       [0.9361313 ],\n",
       "       [0.1453109 ],\n",
       "       [0.68933403],\n",
       "       [0.5483133 ],\n",
       "       [0.93268687],\n",
       "       [0.46837232],\n",
       "       [0.19806129],\n",
       "       [0.32738984],\n",
       "       [0.14336422],\n",
       "       [0.9000361 ],\n",
       "       [0.970676  ],\n",
       "       [0.85374683],\n",
       "       [0.22438505],\n",
       "       [0.9753416 ],\n",
       "       [0.23619433],\n",
       "       [0.54405755],\n",
       "       [0.9382095 ],\n",
       "       [0.98569727],\n",
       "       [0.7426231 ],\n",
       "       [0.4925342 ],\n",
       "       [0.17924163],\n",
       "       [0.43198696],\n",
       "       [0.6450012 ],\n",
       "       [0.4484181 ],\n",
       "       [0.48921528],\n",
       "       [0.61421114],\n",
       "       [0.33217725],\n",
       "       [0.17887825],\n",
       "       [0.43658504],\n",
       "       [0.7006231 ],\n",
       "       [0.7435976 ],\n",
       "       [0.96849906],\n",
       "       [0.3194951 ],\n",
       "       [0.80509007],\n",
       "       [0.56102836],\n",
       "       [0.6535354 ],\n",
       "       [0.9056462 ],\n",
       "       [0.6992774 ],\n",
       "       [0.88655245],\n",
       "       [0.51442873],\n",
       "       [0.943739  ],\n",
       "       [0.2934695 ],\n",
       "       [0.2962806 ],\n",
       "       [0.58973527],\n",
       "       [0.7127503 ],\n",
       "       [0.02014514],\n",
       "       [0.3294245 ],\n",
       "       [0.7716109 ],\n",
       "       [0.6761595 ],\n",
       "       [0.77240396],\n",
       "       [0.58190477],\n",
       "       [0.8741221 ],\n",
       "       [0.7485714 ],\n",
       "       [0.61163336],\n",
       "       [0.6536781 ],\n",
       "       [0.9891451 ],\n",
       "       [0.5528091 ],\n",
       "       [0.1233335 ],\n",
       "       [0.9706661 ],\n",
       "       [0.4321106 ],\n",
       "       [0.4601815 ],\n",
       "       [0.57254344],\n",
       "       [0.4125219 ],\n",
       "       [0.9736738 ],\n",
       "       [0.19844426],\n",
       "       [0.7490533 ],\n",
       "       [0.35828957],\n",
       "       [0.5728424 ],\n",
       "       [0.51047707]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#print(\"acc: \", accuracy_score(y_test, np.array(predicted)))\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#print(\"f1: \",f1_score(y_test, predicted,average=None))\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m sn\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\RoscaMitrut\\.conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\RoscaMitrut\\.conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:319\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    225\u001b[0m     {\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m ):\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\RoscaMitrut\\.conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:94\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     96\u001b[0m             type_true, type_pred\n\u001b[0;32m     97\u001b[0m         )\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    101\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "\n",
    "#print(\"acc: \", accuracy_score(y_test, np.array(predicted)))\n",
    "#print(\"f1: \",f1_score(y_test, predicted,average=None))\n",
    "\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distortions.count(0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
